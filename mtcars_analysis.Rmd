---
title: MPG Analysis on Motor Trends Data"
author: "Ash Chakraborty"
date: "July 24, 2015"
output: html_document:
        toc: true
        theme: cosmo
---

```{r global_options, echo=FALSE, warning=FALSE, message=FALSE, error=FALSE, fig.path="/Figures"}
library(knitr)
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE, error=FALSE, highlight=TRUE)
library(datasets)
data("mtcars")
library(car)
#library(GGally)
library(gplots)
mtcars$am <- as.factor(Recode(mtcars$am, "0='Automatic';1='Manual'"))
```

# Executive Statement

This report looks for the impact on vehicle Miles Per Gallon (MPG) by transmission type (automatic Vs. manual). The dataset used is _Motor Trend_ magazine's _mtcars_ dataset of 1973-74 models.  
Multivariate regression analysis is the strategy used to build competing models in an attempt to incorporate any predictors that confound transmission type's relationship with MPG.

The report concludes _with 95% confidence_ that vehicles with manual transmissions have a statistically significant advantage of **between 0.05 to 5.83 MPG** (holding all other predictors constant) over vehicles that have an automatic transmission. The mean advantage observed in this dataset is **2.94 MPG**.

# Competing Models

## MODEL 0: Base Model

We begin by taking the absolute basic model possible in terms of the response - MPG - and the predictor under investigation - transmission. 

```{r}
model0 <- lm(mpg~am, data=mtcars)
knitr::kable(summary(model0)$coef)
```  

MODEL 0, **mpg = `r signif(summary(model0)$coef[1,1], 3)` + `r signif(summary(model0)$coef[2,1], 3)` . am**

Note: Although this model suggests a significant difference of `r signif(summary(model0)$coef[2,1], 3)` in MPG for manual transmissions as opposed to automatics, the poor R^2^ value is cause for concern. Moreover, a residual plot shows a pattern in error terms, indicating known/unknown confounders. This begs deeper investigation.

## MODEL 1 (STEPWISE ADDITION/ELIMINATION): Arriving at Ideal AIC Value

In order to consider the entire spectrum of possible predictors in the dataset (all are potentials), we perform a step-wise regression on all potential predictors (_mpg~._ model) to iterate through each predictor and fit those with the most optimal AIC value:  

```{r}
model1.step <- step(lm(mpg~., data=mtcars), direction="both", trace=FALSE)
knitr::kable(model1.step$coef)
model1 <- lm(mpg~wt+qsec+am, data=mtcars)
```  

The most optimal model coming out of Stepwise Addition/Elimination is:  

MODEL 1: **mpg = `r signif(summary(model1)$coef[1,1], 3)` - `r signif(summary(model1)$coef[2,1], 3)` . wt + `r signif(summary(model1)$coef[3,1], 3)` . qsec + `r signif(summary(model1)$coef[4,1], 3)` . am**   

Thus, two more predictors have been added to the base model. Note: There's a concern here that the mean MPG for automatic transmissions (the intercept), holding other predictors constant, is _not_ significant.

## MODEL 2 (Linear Correlation): Most Correlated Response-Predictor Pairs

The concern above has led us to look for yet other means of explaining confounding predictors. We turn to linear relationship with the response to help us pick likely candidates. We thus take a look at scatter plots of the response - MPG - against every potential predictor in Figure 1.1 (appendix). We filter predictors based on the following criteria:  

- High _Adjusted R^2^_ (showing a high linear relationship with response)
- Slope coefficient that's significant. 
- Approximate linear relationship with fitted line, few outliers acceptable.  

The candidate predictors from Figure 1.1 to be added to the base model are thus (in decreasing strength of R^2^): **wt, cyl, disp, hp, and drat**. We now use the stepwise addition/elimination process on the potential equation, mpg ~ am + wt + cyl + disp + hp + drat. We get:  

```{r}
model2.step <- step(lm(mpg~am+wt+cyl+disp+hp+drat, data=mtcars), direction="both", trace=FALSE)
knitr::kable(model2.step$coef)
```

We are compelled to force "am" into the model, and thus extract the result from the second-last step the procedure above. Finally, as a guard against _Multicollinearity_. We achieve this by performing a Variance Inflation Test between the predictors and eliminating those that show an abnormal bump in standard deviation:  

```{r}
cat("SD Inflation for Model 2: \n")
knit::kable(sqrt(vif(lm(mpg~am+wt+cyl+hp, data=mtcars))))
```  

After removing the interrelated predictor we arrive at a fairly orthogonal predictor set:
```{r}
model2 <- lm(mpg~wt+hp+am, data=mtcars)
```  

MODEL 2, **mpg = `r signif(summary(model2)$coef[1,1], 3)` - `r signif(summary(model1)$coef[2,1], 3)` . wt - `r signif(summary(model1)$coef[3,1], 3)` . hp + `r signif(summary(model1)$coef[4,1], 3)` . am**   

Note: There's a concern here that the mean MPG difference for manual transmissions, holding other predictors constant, is _not_ significant.

# Refining Models

## Looking for Non-Multicollinearity

Is there any relationship between predictors? I'll test the Variance Inflation in each model.

```{r}
cat('Base Model 0 has only one Predictor. \n')
#knitr::kable(vif(model1))

cat('Model 1 \n')
knitr::kable(sqrt(vif(model1)))

cat('Model 2 \n')
knitr::kable(sqrt(vif(model2)))
```  
None of the models unders consideration have codependent predictors.

### Removing Superfluous Predictors (ANOVA Test)

ANOVA test for Model 1 and Model 2

```{r}
temp <- lm(mpg~am, data=mtcars)
temp1 <- update(temp, mpg~am+wt)
temp2 <- update(temp, mpg~am+wt+qsec)
temp3 <- update(temp, mpg~am+wt+hp)

cat("Model 1 ANOVA: \n")
knitr::kable(anova(temp, temp1, temp2))

cat("Model 2 ANOVA: \n")
knitr::kable(anova(temp, temp1, temp3))

rm(list=c('temp','temp1','temp2','temp3'))
```
We see that in each model, adding the predictors causes significant change in the sum of squares measure. THe models thus stand.

## Residual Diagnostics

Next, we take a loot at some Residual plots to verify that the following assumptions **hold true** for each model:

1. Homoskedasticity
2. Error terms are approximately normally distributed
3. Non-systematic Residuals
4. Id any abnormal leverage points exerting influence

Figure 2.1 generates a grid where a series of residual plots in each column represents one of the competing models. We note the following observations about the models:

Model 1: Linear Correlation Driven | Model 2: Stepwise Algorithm | Model 3: Everything
mpg ~ ...                          | mpg ~ wt + qsec + am        | mpg ~ ...
-----------------------------------|-----------------------------|-----------------------------
Roughly Homoskedastic              | Roughly Homoskedastic       | Roughly Homoskedastic
Normal with High Outliers          | Normal, More Outliers       | Normal, High and Low Outliers
Faint Linear Indication            | Some Linear Indication      | Fairly Non-Systematic
3-4 Potential Leverage Points      | 3-4 Potential Leverage Point| 2 Potential Leverage Points

The residual analysis points to some inherent residual pattern in Model 2 that tells us we're not accounting for some predictor's influence. Overall, Model 3 seems to have a slight edge.

### Evaluating Influence

```{r eval=F}
M1 <- sort(hatvalues(model1), decreasing = T)
M2 <- sort(hatvalues(model2), decreasing = T)
M3 <- sort(hatvalues(model3), decreasing = T)

# cat("Model 1 Potential Influencers \n")
# knitr::kable(mtcars[rownames(mtcars) %in% c("Maserati Bora", "Chrysler Imperial"),])
# 
# cat("Model 2 Potential Influencers \n")
# knitr::kable(mtcars[rownames(mtcars) %in% c("Merc 230", "Chrysler Imperial", "Fiat 128"),])
# 
# cat("Model 3 Potential Influencers \n")
# knitr::kable(mtcars[rownames(mtcars) %in% c("Merc 230", "Chrysler Imperial", "Pantera"),])
```

Figure 2.2 shows us the concerning outlier leverage points in each model. Now, I'll evaluate the influence each outlier might exert on the model...

```{r}
cat("Model 1, Major Leverage and/or Influence \n")
knitr::kable(which(cooks.distance(model1) > (4/(nrow(mtcars)-3-1)) ) )

cat("Model 2, Major Leverage and/or Influence \n")
knitr::kable(which(cooks.distance(model2) > (4/(nrow(mtcars)-3-1)) ) )

cat("Model 3, Major Leverage and/or Influence \n")
knitr::kable(which(cooks.distance(model3) > (4/(nrow(mtcars)-3-1)) ) )

# look at each corresponding observation and make a manual determination on whether or not to remove the outliers.
```

I'm concerned about leverage points that are farther away (larger hat values) that _also_ exert more influence as shown by the Residual Error. This might cause the regression line to bend unfairly towards that value. 

Model 1: While the "Maserati Bora" has a high hatvalue, it's influence (residual error) is fairly low; the Chrysler may be the only candidate to have a somewhat high leverage and influence.

Model 2: The "Merc 230" is a far leverage point with a high influence. It is a candidate for omission.

Model 3: The "Maserati Bora" is a far leverage point with a high influence. It is a candidate for omission.

After reviewing both candidates, I see no reason to eliminate either record as these are not data entry errors. They are merely extreme specimens of the group. **Thus, no further changes are to be made to the models.**

Model 3 is the cleanest in terms of constant variance, non-systematic residuals, approximate normality of errors and outliers with low influence. I pick it as my best fit model.


# Best Fit Model and Results

The best fit model equation looks like...

mpg~am+wt+hp



The response in terms of the transmission looks like (box plot/faceted scatter with regression lines) with confidence and prediction interval ribbons.
The difference between auto and manual is x. This has a 95% conf int of... (t-test)
Restate Assumptions if space permits

# APPENDICES

## MODEL 1: LINEAR CORRELATIONS

### Figure 1.1: Pairs Plot with Adjusted R^2 and Coefficient Significance

This scatterplot produces a pairs plot with the lower panel showing the adjusted R^2 value between response and predictor, as well as coefficient's p-value.

```{r}
# First, I write a function (edited from ?pairs) to display the correlation between response-predictor pairs and it's significance. This function adjusts the font size of the text with the strength of correlation:
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    #r <- abs(cor(y, x))
    r <- signif(summary(lm(y~x))$adj.r.squared, 3)
    r.p <- signif(summary(lm(y~x))$coef[2,4], 4)
    #r.p <- signif(cor.test(y, x, alternative="two.sided", method="pearson")$p.value, 4)
    #p <- round(summary(lm(y~x), data=data.frame(x=x,y=y))$coef[2,4], 4)
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, 'A.r2 = ', txt, '\n p-val = ', r.p)
    if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
    text(0.5, 0.5, txt, cex = cex.cor * r)
}

# function to plot an abline in the pairs plot instead of smoother
panel.line <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
        temp.fit <- lm(y~x, data=data.frame(x=x, y=y))
        
        points(x=x, y=y, pch=21, col='black', bg='yellow')
        abline(a=temp.fit$coef[1], b=temp.fit$coef[2], lwd=1, col='blue')
        
}

#all predictors
pairs(mpg~., data=mtcars, upper.panel=panel.line, cex=.8,cex.labels=2,font.labels=2, lower.panel=panel.cor)
``` 

```{r figure1_1, eval=F}
GGally::ggpairs(data=mtcars, color=mtcars$am,alpha=.2, lower=list(continuous='smooth'), params=c(method='loess'), title="MTCARS LINEAR CORRELATION PAIR CHART: mpg~.")
```

### Figure 2.1: Residual Diagnostic Plots

Plotting Summary Residual Plots for all 3 Models (4 plots each):

```{r}
library(gplots)

par(mfcol=c(5,3), mar=(c(3, 0, 0, 1)))
textplot("Model 0 (Base)", cex=1)
palette(c('cyan','darkgreen','green'))
plot(model0, pch=21, col='black', bg=mtcars$am)

textplot("Model 1 (All Predictors, Step)", cex=1)
palette(c('cyan','darkgreen','green'))
plot(model1, pch=21, col='black', bg=mtcars$am)

textplot("Model 2 (Correlation, Step)", cex=1)
palette(c('cyan','darkgreen','green'))
plot(model2, pch=21, col='black', bg=mtcars$am)
```

### Figure 2.2: Influence and Leverage

Closer look at Leverage points (hatvalues) for each model
```{r eval=F}
boxplot(M1, M2, M3)
text(x=1, y=boxplot(M1, plot=F)$out, labels=names(boxplot(M1, plot=F)[4][[1]]))
text(x=2, y=boxplot(M2, plot=F)$out, labels=names(boxplot(M2, plot=F)[4][[1]]))
text(x=3, y=boxplot(M3, plot=F)$out, labels=names(boxplot(M3, plot=F)[4][[1]]))
```

```{r}
par(mfrow=c(3,1), mar=c(5, 5, 2, 3))
influencePlot(model0, id.col='blue')
influencePlot(model1, id.col='darkgreen')
influencePlot(model2, id.col='brown')
```

